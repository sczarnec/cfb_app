---
title: "CFB Game Predictive Model"
author: ""
date: "2024-10-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Install Packages
```{r}
library(tidyverse)
library(ggplot2)
library(rsample)
library(mice)
library(fastDummies)
library(xgboost)
library(Metrics)
library(caret)
library(httr2)
library(readr)
```

<br>

# *CFB Data Data Prep*

### Load Data

```{r, warning=FALSE}

# model data
cfb_data = read.csv("cfb_project_data_prep_file.csv")[,-1]

```


### Initial Wrangling

```{r}

# df with only rows with both fbs team (fcs data incomplete, easier to exclude these)
# also, let's filter out 
fbs_only = cfb_data %>% 
  filter(t1_division == "fbs" & t2_division == "fbs") %>% 
  select(-c(t1_division, t2_division)) 
  

# treat NAs
model_prepped_orig = fbs_only %>% 
  filter(completed == TRUE) %>% # get rid of non-played games
  select(-c(completed)) %>% # get rid of completed column
  filter(!is.na(t1_rol_pa_pg_l3) & !is.na(t2_rol_pa_pg_l3)) %>% # get rid of games w/o previous game info data
  
  # replace NAs from pbp with lag for each team/season window, both for t1 and t2
  # best estimate of these stats, if available
  group_by(season, t1_team) %>%
  arrange(t1_team, season, week) %>% 
  mutate(across(starts_with("t1"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup() %>% 
  group_by(season, t2_team) %>% 
  arrange(t2_team, season, week) %>% 
  mutate(across(starts_with("t2"), ~ ifelse(is.na(.), lag(.), .))) %>% 
  ungroup()



```


### NA Check

```{r}

# omit NA cols (only one thousand)
model_prepped_omit = na.omit(model_prepped_orig)


# get rid of some cols for now
# will add response vars and descriptive stuff later so we can merge back to our results
response_holder = model_prepped_omit %>% 
  select(c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team))
model_prepped_omit = model_prepped_omit %>% 
  select(-c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team))



# create new df
model_prepped = model_prepped_omit %>% 
  dummy_cols('t1_conference') %>%  # conf dummies
  dummy_cols('t2_conference') %>% 
  select(-c(t1_conference, t2_conference, season_type, t1_points, t2_points)) %>% # useless cols
  mutate(neutral_site = ifelse(neutral_site == TRUE, 1, 0)) %>% # create binary from boolean
  mutate(conference_game = ifelse(conference_game == TRUE, 1, 0))
model_prepped$season = response_holder$season # add back response vars + descriptive stuff
model_prepped$week = response_holder$week
model_prepped$t1_team = response_holder$t1_team 
model_prepped$t2_team = response_holder$t2_team
model_prepped$t1_point_diff = response_holder$t1_point_diff
model_prepped$total_points = response_holder$total_points
model_prepped$t1_win = response_holder$t1_win


```


### Separate Train and Test Data

```{r}

# Split the data by game_id (we want both rows of each game in same training/test sets)
set.seed(792)
split = group_initial_split(model_prepped, group = game_id, prop = 0.7)

# Extract training and test sets
train_orig = training(split) 

train = train_orig %>% 
  select(-c(game_id))



test_orig = testing(split)

test = test_orig %>% 
  select(-c(game_id))

# Check the dimensions of the resulting datasets
dim(train)
dim(test)
```

### Prepare Data for XGBoost
```{r}

# Point Diff

# Create training matrix
pd_train_matrix = xgb.DMatrix(data = as.matrix(train[,1:109]), 
                              label = as.numeric(train$t1_point_diff))

# Create training matrix
pd_test_matrix = xgb.DMatrix(data = as.matrix(test[,1:109]), 
                              label = as.numeric(test$t1_point_diff))




# Total Points

# Create training matrix
pd_train_matrix2 = xgb.DMatrix(data = as.matrix(train[,1:109]), 
                              label = as.numeric(train$total_points))

# Create training matrix
pd_test_matrix2 = xgb.DMatrix(data = as.matrix(test[,1:109]), 
                              label = as.numeric(test$total_points))
```


<br>

# *Point Diff Modeling*



### Tuned Model 

```{r}
set.seed(844)
bst_final <- xgboost(data = pd_train_matrix, # Set training data
              
        
               
              eta = 0.005, # Set learning rate
                     
              max.depth = 3, # Set max depth
              min_child_weight = 5, # Set minimum number of samples in node to split
              gamma = .05, # Set minimum loss reduction for split
              
              
              #alpha = 0.1, 
              #lambda = 1.5,
               
              nrounds = 3507 , # Set number of rounds
              early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
               
              verbose = 1, # 1 - Prints out fit
              nthread = 1, # Set number of parallel threads
              print_every_n = 20, # Prints out result every 20th iteration
              
              eval_metric = "rmse") # Set evaluation metric to use



```

```{r}

boost_preds_final <- predict(bst_final, pd_test_matrix) # Create predictions for xgboost model

pred_dat_final <- cbind.data.frame(boost_preds_final, test$t1_point_diff)

rmse(test$t1_point_diff, boost_preds_final) # print rmse



pred_dat_final <- cbind.data.frame(test$t1_team, test$t2_team, boost_preds_final, test$t1_point_diff, test$week, test$season, test$t1_home)


# modify col names and calculate predicted scores
pred_dat_final = pred_dat_final %>% 
  rename(team1 = `test$t1_team`,
         team2 = `test$t2_team`,
         pred_t1_point_diff = boost_preds_final,
         actual_t1_point_diff = `test$t1_point_diff`,
         week = `test$week`,
         season = `test$season`,
         t1_home = `test$t1_home`) %>% 
  mutate(pred_t1_win = ifelse(pred_t1_point_diff > 0, 1, 0),
         actual_t1_win = ifelse(actual_t1_point_diff > 0, 1, 0),
         pred_t1_point_diff = round(pred_t1_point_diff, 2)) 



```


<br>


# *Future Predictions*

### Load New Data
```{r}
cfb_data_updated = read.csv("cfb_project_data_prep_file_updated.csv")[,-1]


current_season = max(cfb_data_updated$season)
current_week = 15
  #max(cfb_data_updated[cfb_data_updated$season == current_season,]$week)


```


### Filter

```{r}

# filter for next week's game
new_weeks = cfb_data_updated %>% 
  filter(t1_division == 'fbs' & t2_division == 'fbs')%>% 
  select(-c(t1_division, t2_division)) %>% 
  filter(completed == TRUE | (season == current_season & week == current_week))

```


### Re-do Data Prep

```{r}

# redo data prep

# treat NAs
model_prepped_orig_nw = new_weeks %>% 
  select(-c(completed)) %>% # get rid of completed column
  filter(!is.na(t1_rol_pa_pg_l3) & !is.na(t2_rol_pa_pg_l3) & !is.na(t1_.rol_wpa_pp_def)
         & !is.na(t2_.rol_wpa_pp_def)) # get rid of games w/o previous game info data


  

response_holder_nw = model_prepped_orig_nw %>% 
  select(c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team, game_id))

model_prepped_omit_nw = model_prepped_orig_nw %>% 
  select(-c(t1_point_diff, total_points, t1_win, season, week, t1_team, t2_team, game_id))




model_prepped_nw = model_prepped_omit_nw %>% 
  dummy_cols('t1_conference') %>% 
  dummy_cols('t2_conference') %>% 
  select(-c(t1_conference, t2_conference, season_type, t1_points, t2_points)) %>% 
  mutate(neutral_site = ifelse(neutral_site == TRUE, 1, 0)) %>% 
  mutate(conference_game = ifelse(conference_game == TRUE, 1, 0))




model_prepped_nw$season = response_holder_nw$season
model_prepped_nw$week = response_holder_nw$week
model_prepped_nw$t1_team = response_holder_nw$t1_team 
model_prepped_nw$t2_team = response_holder_nw$t2_team
model_prepped_nw$t1_point_diff = response_holder_nw$t1_point_diff
model_prepped_nw$total_points = response_holder_nw$total_points
model_prepped_nw$t1_win = response_holder_nw$t1_win






# Create training matrix
pd_matrix_nw = xgb.DMatrix(data = as.matrix(model_prepped_nw[,1:109]))



```

### Use Model to Predict Week 7 Games

```{r}
# Point Diff

boost_preds_final_nw <- predict(bst_final, pd_matrix_nw) # Create predictions for xgboost model

pred_dat_final_nw <- cbind.data.frame(model_prepped_nw$t1_team, model_prepped_nw$t2_team, boost_preds_final_nw, model_prepped_nw$t1_point_diff, model_prepped_nw$week, model_prepped_nw$season, model_prepped_nw$t1_home)


# modify col names and calculate predicted scores
pred_dat_final_nw = pred_dat_final_nw %>% 
  rename(team1 = `model_prepped_nw$t1_team`,
         team2 = `model_prepped_nw$t2_team`,
         pred_t1_point_diff = boost_preds_final_nw,
         actual_t1_point_diff = `model_prepped_nw$t1_point_diff`,
         week = `model_prepped_nw$week`,
         season = `model_prepped_nw$season`,
         t1_home = `model_prepped_nw$t1_home`) %>% 
  mutate(pred_t1_win = ifelse(pred_t1_point_diff > 0, 1, 0),
         actual_t1_win = ifelse(actual_t1_point_diff > 0, 1, 0),
         pred_t1_point_diff = round(pred_t1_point_diff, 2)) 



```

### Combine All Test Predictions

```{r}
all_predicted = bind_rows(pred_dat_final, pred_dat_final_nw)
```


<br>

# *Betting Lines*

```{r}
historical_odds_orig = read.csv("overall_df.csv")

```

```{r}


# Mapping each college name manually
target_names <- c(
  "Hawai'i", "Jacksonville State", "Tennessee-Martin", "Wake Forest", "Maine", "Central Michigan", 
  "Charlotte", "Indiana", "Appalachian State", "North Carolina State", "Utah State", "Rice", 
  "Vanderbilt", "Southern Utah", "Minnesota", "New Mexico", "UNLV", "Eastern Michigan", 
  "Ball State", "Syracuse", "Temple", "Buffalo", "Michigan State", "Baylor", 
  "Colorado State", "Arkansas State", "Stanford", "Nevada", "Boston College", "Bowling Green", 
  "South Alabama", "Maryland", "Fordham", "Houston", "Michigan", "Purdue", 
  "West Virginia", "Northwestern", "Louisiana", "Virginia Tech", "Villanova", "Air Force", 
  "Rutgers", "LSU", "Ohio", "Miami (OH)", "Oklahoma State", "Virginia", 
  "Murray State", "Kent State", "UCLA", "Louisiana Tech", "UC Davis", "Georgia", 
  "James Madison", "Savannah State", "Troy", "North Carolina Central", "Florida A&M", "Florida Atlantic", 
  "East Carolina", "VMI", "UTSA", "Middle Tennessee", "OK Panhandle", "East Tennessee State", 
  "Tulsa", "Memphis", "Kansas", "SMU", "UCF", "Louisiana-Monroe", 
  "Towson", "Southern Miss", "UMass", "Stephen F. Austin", "Washington State", "UTEP", 
  "Nebraska", "Coastal Carolina", "Alabama", "TCU", "Northern Iowa", "New Hampshire", 
  "Auburn", "BYU", "Wyoming", "Northern Arizona", "Old Dominion", "Notre Dame", 
  "Florida State", "Prairie View A&M", "Pittsburgh", "Charleston Southern", "Mercer", "Akron", 
  "Kentucky", "Navy", "Central Connecticut State", "Wofford", "San Jose State", "Idaho", 
  "Idaho State", "Elon", "North Carolina A&T", "Marshall", "North Texas", "Point University", 
  "McNeese", "Georgia Southern", "South Carolina", "South Florida", "Jacksonville", "Iowa", 
  "Illinois", "Tulane", "Sacramento State", "Texas Tech", "California", "Grambling State", 
  "Clemson", "Georgia State", "North Dakota State", "Toledo", "Monmouth", "San Diego State", 
  "Northern Colorado", "New Mexico State", "Western Michigan", "Texas State", "Oklahoma", "Sam Houston", 
  "Portland State", "USC", "Ole Miss", "Wagner", "Duquesne", "Gardner-Webb", 
  "Western Illinois", "Tennessee", "Boise State", "Missouri", "Colorado", "Nicholls State", 
  "Missouri State", "Houston Christian", "Texas A&M", "Arizona", "Alcorn State", "Georgia Tech", 
  "Kennesaw State", "Robert Morris", "Incarnate Word", "Arizona State", "UConn", "Missouri S&T", 
  "Duke", "Oregon", "Fresno State", "Lafayette", "Western Kentucky", "Miami (FL)", 
  "Oregon State", "Abilene Christian", "Iowa State", "Wisconsin", "Kansas State", "Penn State", 
  "Mississippi State", "Utah", "Texas Southern", "Clark Atlanta", "Presbyterian", "Florida", 
  "Tennessee Tech", "Northwestern State", "Morgan State", "The Citadel", "Central Arkansas", "Hampton", 
  "Chattanooga", "Austin Peay", "Tennessee State", "North Dakota", "Arkansas", "Bethune-Cookman", 
  "Youngstown State", "UAB", "Eastern Washington", "Stony Brook", "Southeastern Louisiana", "Louisville", 
  "Eastern Illinois", "Indiana State", "Morehead State", "Arkansas-Pine Bluff", "Montana", "Army", 
  "Alabama A&M", "Southern University", "Texas", "St. Francis (PA)", "Western Carolina", "Ohio State", 
  "Weber State", "University at Albany", "South Dakota", "South Dakota State", "Lamar", "Campbell", 
  "Lehigh", "Norfolk State", "Florida International", "Colgate", "Drake", "Bucknell", 
  "Montana State", "Illinois State", "Cincinnati", "Eastern Kentucky", "Jackson State", "Cal Poly", 
  "South Carolina State", "Southeast Missouri State", "Delaware", "Reinhardt", "Liberty", "North Alabama", 
  "LIU", "Southern Illinois", "Yale", "Tarleton State", "Utah Tech", "Samford", 
  "Davidson", "Bryant", "East Texas A&M", "Rhode Island", "Tusculum", "Delaware State", 
  "Sacred Heart", "Lindenwood"
)

mapped_names <- c(
  "Hawai'i", "Jacksonville State", "", "Wake Forest", "", "Central Michigan", 
  "Charlotte", "Indiana", "App State", "NC State", "Utah State", "Rice", 
  "Vanderbilt", "", "Minnesota", "New Mexico", "UNLV", "Eastern Michigan", 
  "Ball State", "Syracuse", "Temple", "Buffalo", "Michigan State", "Baylor", 
  "Colorado State", "Arkansas State", "Stanford", "Nevada", "Boston College", "Bowling Green", 
  "South Alabama", "Maryland", "", "Houston", "Michigan", "Purdue", 
  "West Virginia", "Northwestern", "Louisiana", "Virginia Tech", "", "Air Force", 
  "Rutgers", "LSU", "Ohio", "Miami (OH)", "Oklahoma State", "Virginia", 
  "", "Kent State", "UCLA", "Louisiana Tech", "", "Georgia", 
  "James Madison", "", "Troy", "", "", "Florida Atlantic", 
  "East Carolina", "", "UTSA", "Middle Tennessee", "", "", 
  "Tulsa", "Memphis", "Kansas", "SMU", "UCF", "UL Monroe", 
  "", "Southern Miss", "Massachusetts", "", "Washington State", "UTEP", 
  "Nebraska", "Coastal Carolina", "Alabama", "TCU", "", "", 
  "Auburn", "BYU", "Wyoming", "", "Old Dominion", "Notre Dame", 
  "Florida State", "", "Pittsburgh", "", "", "Akron", 
  "Kentucky", "Navy", "", "", "San Jose State", "Idaho", 
  "", "", "", "Marshall", "North Texas", "", 
  "", "Georgia Southern", "South Carolina", "South Florida", "", "Iowa", 
  "Illinois", "Tulane", "", "Texas Tech", "California", "", 
  "Clemson", "Georgia State", "", "Toledo", "", "San Diego State", 
  "", "New Mexico State", "Western Michigan", "Texas State", "Oklahoma", "Sam Houston", 
  "", "USC", "Ole Miss", "", "", "", 
  "", "Tennessee", "Boise State", "Missouri", "Colorado", "", 
  "", "Houston Christian", "Texas A&M", "Arizona", "", "Georgia Tech", 
  "Kennesaw State", "", "", "Arizona State", "UConn", "", 
  "Duke", "Oregon", "Fresno State", "", "Western Kentucky", "Miami", 
  "Oregon State", "", "Iowa State", "Wisconsin", "Kansas State", "Penn State", 
  "Mississippi State", "Utah", "", "", "", "Florida", 
  "", "", "", "", "", "", 
  "", "Austin Peay", "", "", "Arkansas", "Bethune-Cookman", 
  "", "UAB", "", "", "", "Louisville", 
  "", "", "", "", "Montana", "Army", 
  "", "", "Texas", "", "", "Ohio State", 
  "", "", "", "", "", "",
  "", "", "Florida International", "", "", "", 
  "", "", "Cincinnati", "", "", "", 
  "", "", "", "", "Liberty", "", 
  "", "", "", "", "", "", 
  "", "", "", "", "", "", "", ""
)




# combine target names and mapped names into a data frame, each in its own row
# create this data frame
name_change_list_t1 = data.frame(team_one = target_names, team1 = mapped_names) 
name_change_list_t2 = data.frame(team_two = target_names, team2 = mapped_names) 


historical_odds = historical_odds_orig %>% 
  select(team_one, team_two, week, season, home_ml_odds_15, home_ml_money_15, home_ml_tickets_15, away_ml_odds_15, away_ml_money_15, away_ml_tickets_15, home_spread_odds_15, home_spread_value_15, home_spread_money_15, home_spread_tickets_15, away_spread_odds_15, away_spread_value_15, away_spread_money_15, away_spread_tickets_15)
historical_odds = left_join(historical_odds, name_change_list_t1, by = "team_one")
historical_odds = left_join(historical_odds, name_change_list_t2, by = "team_two")
historical_odds_t1 = historical_odds %>% select(-team_one, -team_two)
historical_odds_t2 = historical_odds_t1 %>% rename(team2 = team1, team1 = team2)
historical_odds = bind_rows(historical_odds_t1, historical_odds_t2)





### GO BACK AND MATCH WEEKS, COULD BE CAUSING NULLS

pred_odds_comb = left_join(all_predicted, historical_odds, by = c("team1", "team2", "week", "season"))







```

```{r}

# # Calculate the percentage of NAs in each column
# na_rate <- colMeans(is.na(pred_odds_comb %>% filter(season>2015)))
# 
# # Create a new data frame with the NA percentages
# df_na_percentage <- data.frame(
#   column = colnames(pred_odds_comb),
#   na_rate = na_rate
# )
# 
# # display
# df_na_percentage %>% 
#   arrange(desc(na_rate))



# is 3,000 obs enough? work cutting down by 1k for betting data? ask martin
```

```{r}

app_historical_df = pred_odds_comb %>% 
  filter(t1_home == 1) %>% 
  select(-c(away_ml_money_15, away_ml_tickets_15, home_ml_money_15, home_ml_tickets_15, away_spread_money_15, away_spread_tickets_15, home_spread_tickets_15, home_spread_money_15)) %>% 
  select(-t1_home) %>% 
  mutate(book_home_ml_odds = home_ml_odds_15,
         book_away_ml_odds = away_ml_odds_15,
         book_home_spread = home_spread_value_15,
         book_home_spread_odds = home_spread_odds_15,
         book_away_spread = away_spread_value_15,
         book_away_spread_odds = away_spread_odds_15
         ) %>% 
  select(-c(away_spread_value_15, home_ml_odds_15, away_ml_odds_15, home_spread_value_15, 
            home_spread_odds_15, away_spread_odds_15)) %>% 
  rename(pred_home_point_diff = pred_t1_point_diff,
         home_team = team1,
         away_team = team2,
         actual_home_point_diff = actual_t1_point_diff,
         pred_home_win = pred_t1_win,
         actual_home_win = actual_t1_win) %>% 
  mutate(pred_home_spread = pred_home_point_diff * -1,
         actual_home_spread = actual_home_point_diff * -1) %>%
  select(-c(pred_home_point_diff, actual_home_point_diff)) %>% 
  mutate(pred_home_cover = ifelse(pred_home_spread > book_home_spread, 1, 0),
         actual_home_cover = ifelse(actual_home_spread > book_home_spread, 1, 0)) %>% 
  mutate(spread_correct = ifelse(pred_home_cover == actual_home_cover, 1, 0),
         spread_winnings = ifelse(spread_correct == 1 & pred_home_cover == 1 & book_home_spread_odds > 0, 
                                  1 + abs(book_home_spread_odds)/100,
                            ifelse(spread_correct == 1 & pred_home_cover == 1,
                                   1 + 100/abs(book_home_spread_odds),
                            ifelse(spread_correct == 1 &  book_away_spread_odds > 0, 
                                  1 + abs(book_away_spread_odds)/100,
                            ifelse(spread_correct == 1,
                                   1 + 100/abs(book_away_spread_odds),
                            0))))) %>% 
  mutate(ml_correct = ifelse(pred_home_win == actual_home_win, 1, 0),
         ml_winnings = ifelse(ml_correct == 1 & pred_home_win == 1 & book_home_ml_odds > 0, 
                                  1 + abs(book_home_ml_odds)/100,
                            ifelse(ml_correct == 1 & pred_home_win == 1,
                                   1 + 100/abs(book_home_ml_odds),
                            ifelse(ml_correct == 1 &  book_away_ml_odds > 0, 
                                  1 + abs(book_away_ml_odds)/100,
                            ifelse(ml_correct == 1,
                                   1 + 100/abs(book_away_ml_odds),
                            0))))) %>% 
  mutate(naive_spread_winnings = ifelse(actual_home_cover == 1 & book_home_spread_odds > 0, 
                                  (1 + abs(book_home_spread_odds)/100)/2,
                            ifelse(actual_home_cover == 1,
                                   (1 + 100/abs(book_home_spread_odds))/2,
                            ifelse(book_away_spread_odds > 0, 
                                  (1 + abs(book_away_spread_odds)/100)/2, 
                            (1 + 100/abs(book_away_spread_odds))/2
                            )))) %>% 
  mutate(naive_ml_winnings = ifelse(actual_home_win == 1 & book_home_ml_odds > 0, 
                                  (1 + abs(book_home_ml_odds)/100)/2,
                            ifelse(actual_home_win == 1,
                                   (1 + 100/abs(book_home_ml_odds))/2,
                            ifelse(book_away_ml_odds > 0, 
                                  (1 + abs(book_away_ml_odds)/100)/2,
                            (1 + 100/abs(book_away_ml_odds))/2
                            )))) %>% 
  mutate(pred_vs_book_spread = abs(pred_home_spread - book_home_spread))
  
  




# sum(app_historical_df$ml_winnings, na.rm = TRUE)
# length(filter(app_historical_df, !is.na(ml_winnings))$ml_winnings)
# 
# 
# sum(app_historical_df$spread_winnings, na.rm = TRUE)
# length(filter(app_historical_df, !is.na(ml_winnings))$spread_winnings)
# 
# 
# 
# 
# sum(app_historical_df$naive_ml_winnings, na.rm = TRUE)
# length(filter(app_historical_df, !is.na(ml_winnings))$ml_winnings)
# 
# 
# sum(app_historical_df$naive_spread_winnings, na.rm = TRUE)
# length(filter(app_historical_df, !is.na(ml_winnings))$spread_winnings)


#length(na.omit(app_historical_df)$week)





```


```{r}
# write app_historical_df to a csv
write.csv(app_historical_df, "app_historical_df.csv", row.names = FALSE, quote = FALSE, fileEncoding = "utf-8")



colnames(app_historical_df)
```













